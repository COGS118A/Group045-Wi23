{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sang Tran\n",
    "- Tej Nair\n",
    "- Angel Olivas\n",
    "- Stanley Sisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tittle\n",
    "Revisiting Interpretation Of Blood Cholesterol Level As A Risk Factor For Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "    \n",
    "   Studying heart disease is vital as it is the leading cause of death as physicians have recognized for decades that one is only as old as their arteries. Knowing the causes and risk factors can help prevent and treat it effectively, or at best, lengthen human healthspan by preventive measures. With regards to aging related health issues, it can be difficult to pinpoint particular causing factors because there can be a variety of possible confounding variables to consider. Although it has been widely believed that serum cholestoral level in the blood is one of the first attributes doctors will look at to predict one's chances of having cardiovascular diseases. With the biniary classification label UCI heart disease dataset obtained from 1988 that comes from four databases: Cleveland, Hungary, Switzerland, and Long Beach V, this paper goal is to see whether or not including serum cholestoral level in training will have a additive predictive effect on presence of heart disease in the patient. Voting classifier, whose estimators consist of logistic regression, support vector machine, k-nearest neighbors, random forest, adaboost, and xgboost, will be used for better prediction outcomes. Random search cross validation for the best hyper-parameters of the individual classifier will be conducted and finalized tuned model with voting classifier will be compared first with the base model with voting classfier and then the benchmark models. The performance evaluation metrics will be used are accuracy, recall, precision, f1-score and AUC-ROC Curve.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Cholesterol is an essential lipid found in our body and in all of human body's cells. Human body needs cholesterol to make hormones, vitamin D, and substances that aid digestion. Ever since first study on correlation between serum cholesterol level in the blood and cardiovascular disease was published in 1986 <a name=\"clark\"></a>[<sup>[1]</sup>](#clarknote), a widely adopted views by physicians and currrent literatures that high levels of cholesterol increase one's risk of heart disease, and stroke. The two main types of cholesterol are LDL (which are usually considered bad cholesterol in the literature) and HDL (good cholesterol). LDL cholesterol is found to be associated with an increased risk of heart disease and other health problems, while HDL cholesterol is associated with a decreased risk of such health complications. Other types of cholesterol include triglycerides and very low-density lipoprotein (VLDL) cholesterol. Triglycerides and LDL (low-density lipoprotein) are both types of lipids, or fats, found in the bloodstream. The main difference between the two is their composition and the way they are transported in the body. Triacylglycerols, which consist of three fatty acids, are the main form of fat stored in cells and are usually derived from dietary sources. LDL particles are composed of a core of cholesterol and a combination of triglycerides, phospholipids, and proteins. They play an important role in transporting cholesterol from the liver to other parts of the body. LDL cholesterol is transported from the liver to cells throughout the body and helps the body convert dietary fat into energy for the cells, thus when physicians warn patients of elevated levels of cholesterol, they usually mean high levels LDL.\n",
    "\n",
    "Into the early 2020s, with the rise of adoption of different dietary lifestyles such as ketogenic diet, carnivore diet and many variants between the two. The traditionally held belief on correlation between blood cholesterol level and heart disease has been challenged. A study in 2020 shows that low carbohydrate diets, which consists mainly animal fats or plant fats , in fact has a beneficial effect on cardiovascular risk factors <a name=\"dong\"></a>[<sup>[2]</sup>](#dongnote). In this particular area of research, it takes a lot of time, effort and money to carry out longitudial study. With the astronomical increase in research papers published every year, we are in a replication crisis <a name=\"wiki\"></a>[<sup>[3]</sup>](#wikipedia) and as noted by many intellectuals in the 21st century, this topic has been explored and discussed in great depth in the POS Medicine journal article  explaining why most of studies' findings are not reliable <a name=\"ioannidis\"></a>[<sup>[4]</sup>](#ioannidisjpa).\n",
    "\n",
    "In terms of dietary cholesterol, a paper <a name=\"soliman\"></a>[<sup>[5]</sup>](#solimannote) in 2018 concluded that dietary cholesterol does not increase heart disease risk in healthy individuals, but saturated fatty acids and trans-fats do. The inter-presence between cholesterol and saturated fatty acids in food may have led to the misconception that dietary cholesterol is harmful. This still implicitly suggests the current view is correct that physicians still should keep blood cholesterol levels in people that are not healthy in check, and in essense, does not explain when such readings will give insightful interpretation because definition of a \"healthy\" person can be varying by different physicians.\n",
    "\n",
    "In terms of serum cholesterol levels, although there are many subcatergories and types of cholesterol, current concensus on which one is the culprit has been recently debated and the one that gains most attention is LDL-C, low density lipoprotein cholesterol, which is considered very bad because it is hypothesized by many that they easily get into any blood vessels due to its low density structures. However, recent finding in 2022 <a name=\"rcsi\"></a>[<sup>[6]</sup>](#rcsinote) found that there is a very weak link in predicting cardiovascular disease based on LDL-C.  \n",
    "\n",
    "There are several limitations to the studies in this area of research. One that is worth noting is the number of observations can be very scarce because people do not have their lipid profile done annually until their doctors think that they show heart disease related symtoms. Replication from a different population should be conducted to generalize results, which can be time consuming and needs a lot of funding. \n",     
    "\n",
    "Two best previous works on finding best classification model on the same dataset both shows about 90% accuracy and recall on average. Bhat's work <a name=\"Bhat\"></a>[<sup>[7]</sup>](#Bhatnote) uses ensembling method for the best three out of seven classifiers used to finalize the model while Rutecki <a name=\"Rutecki\"></a>[<sup>[8]</sup>](#Rutecki) uses voting classifier that comprises of ten estimators, which also produces about similar scores for both soft and hard voting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In the face of overwhelmingly contradictory findings from the literature in medicine and nutrition, two questions can be raised. First, whether dietary fats have influences on blood serum cholesterol levels since most of the time the number one lifestyle advice physicians give to patients with elevated levels to fix is to stay away foods that are high on fats. Second, whether cholesterol level in the blood is a good predictor of one's risk of heart disease. The former question should only be taken seriously if indeed there is a positive correlation between blood serum cholesterol level and heart disease.\n",
    "\n",
    "A hypothesis that this paper will attempt to test is that serum cholesterol level in the blood is not a significantly strong predictor of presence of heart disease in patients in our dataset. In other words, we will attempt to find the best model leaving out serum cholesterol level feature while keeping the rest to classify the labels.    \n",
    "\n",
    "By providing results from this hypothesis testing, we can contribute to the reconsideration of interpretation of blood serum cholesterol as a risk factor for heart disease. This hypothesis can be reproduced and replicable for those with our dataset which are available and can be obtained for free from online <a name=\"data\"></a>[<sup>[9]</sup>](#datasetnote). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "- In the original heart disease dataset <a name=\"uci\"></a>[<sup>[10]</sup>](#ucidata) from UCI archive, it contains 76 attributes, but all published experiments refer to using a subset of 14 of them.\n",
    "- In the dataset obtained <a name=\"data\"></a>[<sup>[9]</sup>](#datasetnote) there are 14 variables and 1025 observations. Each observation consists of age (numerical), sex (catergorical), chest pain type (catergorical), resting blood pressure (numerical), serum cholestoral (numerical), fasting blood sugar (numerical), resting electrocardiographic results (catergorical), maximum heart rate achieved (numerical), exercise induced angina (catergorical), oldpeak (numerical), the slope of the peak exercise ST segment (catergorical), number of major vessels (catergorical), thal (catergorical), target (catergorical).\n",
    "- The target field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.\n",
    "- Some data cleaning that we will do: check and drop duplicates, check and drop rows with missing values, check if variance of any feature column equals to 0, drop cholesterol column, change the features' names to (Age, Sex, ChestPainType, RestingBP, FastingBS, RestingECG, MaxHR, ExerciseAngina, Oldpeak, ST_Slope, Target).\n",
    "<br> <br> \n",
    "Dataset Attributes:\n",
    "- Age (years)\n",
    "- Sex (1 = Male; 0 = Female)\n",
    "- ChestPainType (chest pain type, 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-Anginal Pain, 3 = Asymptomatic)\n",
    "- RestingBP (resting blood pressure, measured in mg/dl)\n",
    "- Cholesterol (serum cholestoral measured in mg/dl)\n",
    "- FastingBS (fasting blood sugar, measured in mg/dl; = 1: if FastingBS > 120 mg/dl, = 0: otherwise)\n",
    "- RestingECG (resting electrocardiographic results; 0 = Normal, 1 = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria values) \n",
    "- MaxHR (maximum heart rate achieved, numeric value between 60 and 202)\n",
    "- ExerciseAngina (exercise induced angina, 1 = Yes, 0 = No)\n",
    "- Oldpeak (ST depression induced by exercise relative to rest, numeric value measured in depression) \n",
    "- ST_Slope (the slope of the peak exercise ST segment, 2 = Upsloping, 0 = Flat, 2 = Downsloping) \n",
    "- N_MajorVessels (number of major vessels colored by flourosopy, values: 0-3)\n",
    "- Thal (thal; 0 = normal, 1 = fixed defect(no blood flow in some part of the heart), 2 = reversable defect(a blood flow is observed but it is not normal))\n",
    "- HeartDisease (target, 1: Heart disease, 0: Normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our proposed solution to the problem is to use voting classifier to predict whether a patient has heart disease without cholesterol feature. Results from our model will be compared to the accuracy, recall, precision, f1-score and ROC-AUC of two benchmark models on kaggle as discussed above. Besides, we will default to using significance level of 0.05 and t student test statistic to decide whether we should reject the null hypothesis in favor of our alternative based on the assumptions that the average accuracy score from the benchmark models is the current threshold. \n",
    "\n",
    "For our classifier, we will use combination logistic regression, support vector machine, random forest, k-nearest neighbors, adaboost, and xgboost, will be used. We will use random search for the best set of hyper-parameters in the random search space instead of exhaustive search for each of our classifier in the voting classifier since we are deal with a number of them. We specify the number of iterations depending on the runtime of each classifier for the random search to try before returning the best model. \n",
    "\n",
    "Reasons for choosing the above estimators are because logistic regression is used to classify binary labels as probability, support vector machine is effective in high dimensional feature spaces, kNN is appropriate to used since we prefer high accuracy and the others (random forest, adaboost, and xgboost) are more accurate when it comes to classifying labels with a mixture numerical and categorical features or just numeric features. Since the number of observations are limited, we will use repeated k-fold cross-validation on recall with default k=5 to evaluate the model's ability to predict on new data. Since heart attack is a life threatening event, or false negatives should be penalized in this context, it is sensible for us to compare average recall scores. Random search CV will search for the best set of hyper parameters for each classifier passed to the voting classifier based on the arguments allowed on scikit-learn library. \n",
    "\n",
    "Libraries will be used are scikit-learn, xgboost, pandas, numpy and matplotlib. All the machine learning algorithms will be called via scikit-learn library.<br>\n",
    "Functions to call to fit data are:<br>\n",
    "- sklearn.linear_model.LogisticRegression()<br>\n",
    "- sklearn.svm.SVC()<br>\n",
    "- sklearn.neighbors.KNeighborsClassifier()<br>\n",
    "- sklearn.ensemble.RandomForestClassifier()<br>\n",
    "- sklearn.ensemble.AdaBoostClassifier()<br>\n",
    "- xgboost.XGBClassifier()<br>\n",
    "- sklearn.ensemble.VotingClassifier()<br>\n",
    "- sklearn.model_selection.train_test_split()<br>\n",
    "- sklearn.model_selection.cross_val_score()<br>\n",
    "\n",
    "We will use train-test-split for model selection with test size of 0.2 and keep default values for individual estimators for the base model. Then we will use random search for best hyper-parameters for each estimator. We expect our tuned model to perform better than the base, and thus will compare with the benchmark models, whose statistics are described below.\n",
    "\n",
    "The benchmark models:<br><br>\n",
    "- By Bhat:<br>\n",
    "\n",
    "_accuracy  : 91.8%<br>\n",
    "_precision : 91.4%<br>\n",
    "_recall    : 94.1%<br> \n",
    "_f1-score  : 92.7%<br><br>\n",
    "\n",
    "- By Rutecki:<br>\n",
    "\n",
    "Hard Voting:<br> \n",
    "_accuracy  : 89.7%<br>\n",
    "_precision : 89.6%<br>\n",
    "_recall    : 92.0%<br>\n",
    "_f1-score  : 90.8%<br>\n",
    "_Average Cross Validation Recall score:  89.0%<br><br>\n",
    "Soft Voting:<br> \n",
    "_accuracy  : 90.8%<br>\n",
    "_precision : 91.4%<br> \n",
    "_recall    : 92.0%<br> \n",
    "_f1-score  : 91.7%<br>\n",
    "_Average Cross Validation Recall score:  87.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will use accuracy, recall, precision, f1-score and average cross validation recall score to compare the models. Making use of built in functions in scikit-learn library to compute confusion matrix, number of true poitives (TP), true negatives (TN), false positives (FP) and false negatives (FN). The mathematical equations are expressed as follows:<br>\n",
    "Accuracy  = (TN + TP) / (TP + TN + FP + FN)<br>\n",
    "Precision = TP / (TP + FP)<br>\n",
    "Recall    = TP / (TP + FN)<br>\n",
    "F1-score  = 2 * Precision * Recall / (Precision + Recall)\n",
    "\n",
    "We also use the AUC-ROC Curve to assess the overall diagnostic performance of the models, using scikit-learn library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data, Perform Data Cleaning, And Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "rawdata = pd.read_csv('Heart_Disease_Dataset.csv')\n",
    "feature_names = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \n",
    "                 \"RestingECG\", \"MaxHR\", \"ExerciseAngina\", \"Oldpeak\", \"ST_Slope\", \"N_MajorVessels\", \"Thal\", \"HeartDisease\"]\n",
    "data = rawdata\n",
    "data.columns = feature_names\n",
    "data = data.drop(columns=['Cholesterol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check duplicates\n",
    "sum(data.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete duplicates and reset index\n",
    "data = data.drop_duplicates(keep='first')\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Value Detection\n",
    "assert data.isnull().sum().all() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 138, 1: 164})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Balances In The Number Of Class 0 And Class 1 \n",
    "from collections import Counter\n",
    "print(data['HeartDisease'].unique())\n",
    "Counter(data['HeartDisease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the number of observations of target label 0 not significatly different to that of target label 1 (ratio about 1 to 1.2), we will not have to worry too much about imbalanced data issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[\"HeartDisease\"]\n",
    "X = data.drop('HeartDisease',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that have very little difference or diversity in the data do not contribute any useful information for an ML model to learn patterns. If a feature has the same value (e.g., 2) for every observations in a dataset, it is considered a constant feature and does not provide any significant value. It is important to remove such features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check variance of each feature column to see if there is any that equals to 0\n",
    "assert X.var().any() > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 113, 1: 128})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Check Balances In The Number Of Class 0 And Class 1 for training\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/stt008/.local/lib/python3.9/site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = [('LogisticRegression', LogisticRegression()), ('RandomForest', RandomForestClassifier()), \n",
    "             ('SVC', SVC(kernel='rbf', probability = True)), ('KNN', KNeighborsClassifier()),\n",
    "             ('AdaBoostClassifier', AdaBoostClassifier()), ('XGB', XGBClassifier())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model With Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0e802a8130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "VC_base = VotingClassifier(estimators = estimator, voting = 'soft')\n",
    "VC_base.fit(X_train, y_train)\n",
    "y_pred = VC_base.predict(X_test)\n",
    "VC_base_Recall = recall_score(y_test, y_pred)\n",
    "VC_base_Precision = precision_score(y_test, y_pred)\n",
    "VC_base_f1 = f1_score(y_test, y_pred)\n",
    "VC_base_accuracy = accuracy_score(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall scores are: [0.88461538 0.8        0.84       0.84615385 0.84615385]\n",
      "Average Cross Validation Recall score:  0.8433846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(VC_base, X_train, y_train, cv=5, scoring='recall')\n",
    "VC_base_cv_score = score.mean()\n",
    "print('Cross Validation Recall scores are: {}'.format(score))\n",
    "print('Average Cross Validation Recall score: ', VC_base_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:    0.86\n",
      "Precision: 0.82\n",
      "F1-score:  0.84\n",
      "Accuracy:  0.80\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall:    {VC_base_Recall:.2f}')\n",
    "print(f'Precision: {VC_base_Precision:.2f}')\n",
    "print(f'F1-score:  {VC_base_f1:.2f}')\n",
    "print(f'Accuracy:  {VC_base_accuracy:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Curve for Voting Classifier with base model: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC_score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC-ROC Curve for Voting Classifier with base model: {ROC_AUC_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba = VC_base.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "def plot_auc_roc_curve(y_test, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "plot_auc_roc_curve(y_test, y_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8299036281179138\n",
      "Best Hyperparameters: {'C': 0.0009542204902104136, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.model_selection import RepeatedKFold \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=0)\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "lr_space = dict()\n",
    "lr_space['solver']  = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lr_space['penalty'] = ['none','l1', 'l2', 'elasticnet']\n",
    "lr_space['C']       = loguniform(1e-5, 100)\n",
    "search_lr = RandomizedSearchCV(model_lr, lr_space, n_iter=1000, scoring='accuracy', cv=cv, random_state=0)\n",
    "result = search_lr.fit(X_train, y_train)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8312641723356009\n",
      "Best Hyperparameters: {'C': 0.3320922888698161, 'gamma': 0.011564063794438945, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC()\n",
    "svc_space = dict()\n",
    "svc_space['C']      = loguniform(1e-5, 100)\n",
    "svc_space['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svc_space['gamma']  = loguniform(1e-5, 100) \n",
    "search_svc = RandomizedSearchCV(model_svc, svc_space, n_iter=1000, scoring='accuracy', cv=cv, random_state=0)\n",
    "result = search_svc.fit(X_train, y_train)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8256519274376418\n",
      "Best Hyperparameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 59, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 365}\n"
     ]
    }
   ],
   "source": [
    "model_rfr = RandomForestClassifier()\n",
    "rfr_space = dict()\n",
    "rfr_space['n_estimators']      = randint(100,500)\n",
    "rfr_space['criterion']         = ['gini', 'entropy', 'log_loss']\n",
    "rfr_space['max_depth']         = randint(30,100)\n",
    "rfr_space['max_features']      = ['sqrt', 'auto'] \n",
    "rfr_space['min_samples_split'] = [2, 5, 10]\n",
    "rfr_space['min_samples_leaf']  = [1, 2, 4]\n",
    "rfr_space['bootstrap']         = [True, False]\n",
    "search_rfr = RandomizedSearchCV(model_rfr, rfr_space, n_iter=10, scoring='accuracy', cv=cv, random_state=0)\n",
    "result = search_rfr.fit(X_train, y_train)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For K-Nearest Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8479024943310658\n",
      "Best Hyperparameters: {'algorithm': 'ball_tree', 'leaf_size': 560, 'n_neighbors': 22, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "knn_space = dict()\n",
    "knn_space['n_neighbors'] = randint(1,33)\n",
    "knn_space['weights']     = [\"uniform\", \"distance\"]\n",
    "knn_space['algorithm']   = [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "knn_space['leaf_size']   = randint(1,1000) \n",
    "knn_space['p']           = [1,2]\n",
    "search_knn = RandomizedSearchCV(model_knn, knn_space, n_iter=1000, scoring='accuracy', cv=cv, random_state=0)\n",
    "result = search_knn.fit(X_train, y_train)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search For XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model With Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons Between Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying heart disease datasets may raise several ethical issues that need to be addressed to ensure that the research is conducted in a responsible and ethical manner. Some of the ethical issues that may arise in studying heart disease datasets are:\n",
    "\n",
    "- Informed consent: The issue of informed consent arises when researchers collect and use patient data without their knowledge or permission. Researchers should obtain informed consent from patients before collecting and using their data.\n",
    "\n",
    "- Confidentiality and privacy: Patient data should be kept confidential and private to protect their privacy. Researchers should take appropriate measures to ensure that patient data is not disclosed or shared with unauthorized persons.\n",
    "\n",
    "- Data bias: There is a risk of data bias when datasets are not representative of the population being studied. Researchers should ensure that datasets are diverse and representative to avoid biases.\n",
    "\n",
    "- Data ownership: Ownership of the data is an important issue when studying heart disease datasets. Researchers should respect the ownership rights of the patients and the institutions that provided the data.\n",
    "\n",
    "- Data security: There is a risk of data breaches when working with large datasets. Researchers should take appropriate measures to ensure the security of the data and prevent unauthorized access.\n",
    "\n",
    "- Data accuracy and validity: The accuracy and validity of the data are important for drawing reliable conclusions from the research. Researchers should ensure that the data is accurate and valid and that any errors or discrepancies are corrected.\n",
    "\n",
    "- Fair distribution of benefits: The benefits of the research should be fairly distributed among all parties involved. Patients should be informed about the benefits and risks of the research, and their rights should be protected. Researchers should ensure that the benefits of the research are distributed fairly among all parties involved.\n",
    "\n",
    "Addressing these ethical issues is critical for conducting responsible and ethical research on heart disease datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show up to meetings as planned\n",
    "* Finish the work assigned to each team members\n",
    "* Communicate through discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/21  |  8 PM |  Do background research on topic (all) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/22  | 7 PM  | Edit, finalize, and submit proposal; Search for datasets (all)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/6  | 7 PM  | Import & Wrangle Data ,do some EDA (all) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/8  | 9 PM  | Finalize wrangling/EDA; Begin programming for project (all)  | Discuss/edit project code; Complete and Submit Checkpoint |\n",
    "| 3/15  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (all) | Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"clarknote\"></a> 1.[^](#clark): Clark LT (1986). Cholesterol and heart disease: current concepts in pathogenesis and treatment. J Natl Med Assoc. 1986 Aug;78(8):743-51. PMID: 3531531; PMCID: PMC2571342. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2571342/<br> \n",
    "\n",
    "<a name=\"dongnote\"></a> 2.[^](#dong): Dong T, et al. (2020). The effects of low-carbohydrate diets on cardiovascular risk factors: A meta-analysis. PLoS One. 2020 Jan 14;15(1):e0225348. doi: 10.1371/journal.pone.0225348. PMID: 31935216; PMCID: PMC6959586. https://pubmed.ncbi.nlm.nih.gov/31935216/<br>\n",
    "\n",
    "<a name=\"wikinote\"></a> 3.[^](#wikipedia): Wikipedia (2023). Replication crisis. Wikipedia. Available at: https://en.wikipedia.org/wiki/Replication_crisis#References (Accessed: March 3, 2023)<br>\n",
    "\n",
    "<a name=\"ioannidisjpda\"></a> 4.[^](#ioannidis): Ioannidis JPA (2005). Why Most Published Research Findings Are False. PLOS Medicine 2(8): e124. https://doi.org/10.1371/journal.pmed.0020124<br>\n",
    "\n",
    "<a name=\"solimannote\"></a> 5.[^](#soliman): Soliman GA (2018). Dietary Cholesterol and the Lack of Evidence in Cardiovascular Disease. Nutrients. 2018 Jun 16;10(6):780. doi: 10.3390/nu10060780. PMID: 29914176; PMCID: PMC6024687. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6024687/<br> \n",
    "\n",
    "<a name=\"rcsinote\"></a> 6.[^](#rcsi): ScienceDaily (2022). Link between high cholesterol and heart disease 'inconsistent', new study finds (2022) ScienceDaily. Available at: https://www.sciencedaily.com/releases/2022/03/220314120702.htm (Accessed: March 3, 2023)<br> \n",
    "\n",
    "<a name=\"Bhatnote\"></a> 7.[^](#Bhat): Bhat N. EDA+Classification+Ensemble ~ 92% Accuracy. Kaggle. Available at: https://www.kaggle.com/code/nareshbhat/eda-classification-ensemble-92-accuracy/notebook (Accessed: March 6, 2023)<br>\n",
    "\n",
    "<a name=\"Ruteckinote\"></a> 8.[^](#Rutecki): Rutecki M. Voting Classifier for Better Results. Kaggle. Available at: https://www.kaggle.com/code/marcinrutecki/voting-classifier-for-better-results#4.-Model-selection (Accessed: March 6, 2023)<br>\n",
    "\n",
    "<a name=\"rcsinote\"></a> 9.[^](#rcsi): Lapp D. Heart Disease Dataset. Kaggle. Available at: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset?resource=download (Accessed: March 1, 2023)<br> \n",
    "\n",
    "<a name=\"Duanote\"></a>10.[^](#Dua): Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
